---
title: "Textures"
excerpt_separator: "<!--more-->"
categories:
 - OpenGL 
tags:
 - opengl
---
{% include mathJax.html %}

A texture is a 2D image (even 1D and 3D textures exist) used to add detail to an object

<!--more-->

**Table of Contents**
* TOC
{:toc}

## Textures
A texture is a 2D image (even 1D and 3D textures exist) used to add detail to an object; think of a texture as a piece of paper with a nice brick image (for example) on it neatly folded over your 3D house so it looks like your house has a stone exterior.

## Texture Mapping
In order to map a texture to the triangle we need to tell each vertex of the triangle which part of the texture it corresponds to. 

Each vertex should thus have a texture coordinate associated with them that specifies what part of the texture image to sample from. **Fragment interpolation** then does the rest for the other fragments.

In OpenGL, texture coordinates are used to map textures to objects, defining how a texture should be applied to a shape. Texture coordinates range from [0,0] to [1,1]  where:
(0, 0) represents the bottom-left corner of the texture.
(1, 1) represents the top-right corner of the texture.
{: .notice--success}

Texture coordinates range from 0 to 1 in the x and y axis (remember that we use 2D texture images). Retrieving the texture color using texture coordinates is called **sampling.** 

Texture coordinates start at (0,0) for the lower left corner of a texture image to (1,1) for the upper right corner of a texture image. The following image shows how we map texture coordinates to the triangle:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl8.png)

We specify 3 texture coordinate points for the triangle. 

1. Bottom-left side of the triangle to correspond with the bottom-left side of the texture so we use the (0,0) texture coordinate for the triangle's bottom-left vertex. 
2. Bottom-right side with a (1,0) texture coordinate.
3. The top of the triangle should correspond with the top-center of the texture image so we take (0.5,1.0) as its texture coordinate.

The resulting texture coordinates would then look like this:

```cpp
float texCoords[] = {
    0.0f, 0.0f,  // lower-left corner  
    1.0f, 0.0f,  // lower-right corner
    0.5f, 1.0f   // top-center corner
};
```

### Example: Mapping a Texture onto a Quad
Imagine a quad that has four vertices and you want to map a texture onto it:

```cpp
// Vertex positions (for a quad)
float vertices[] = {
    // positions        // texture coordinates
    0.5f,  0.5f, 0.0f,  1.0f, 1.0f,  // top right
    0.5f, -0.5f, 0.0f,  1.0f, 0.0f,  // bottom right
   -0.5f, -0.5f, 0.0f,  0.0f, 0.0f,  // bottom left
   -0.5f,  0.5f, 0.0f,  0.0f, 1.0f   // top left
};
```

## Texture Sampling
Retrieving a color from the texture using texture coordinates is known as sampling. The process involves taking the **texture coordinates** provided by each vertex and using them to fetch a color from the texture image in the **fragment shader.**

For example, when you provide the texture coordinates to a sampler (such as `sampler2D` in GLSL), OpenGL looks up the color in the texture at those coordinates:

```cpp
#version 330 core

in vec2 TexCoord;           // Texture coordinate for the current fragment
out vec4 FragColor;         // Final color of the fragment

uniform sampler2D ourTexture; // Texture sampler - which we setup the Texture from the CPU Side

void main()
{
    FragColor = texture(ourTexture, TexCoord); // Sample and set the color - grabs the interpolated texture color
}
```

### Texture Sampling - How It works?

1. **Texture Coordinates on Vertices:** You define specific texture coordinates for each vertex of your shape (for example, each corner of a quad might have coordinates like (0, 0), (1, 0), (1, 1), and (0, 1) to map the entire texture onto the quad).
2. **Interpolation Across Fragments:** When the shape is rasterized (converted into fragments), OpenGL interpolates these texture coordinates between vertices. This means every fragment gets its own interpolated texture coordinate based on the position between vertices.
3. **Sampling the Texture:** In the fragment shader, each interpolated texture coordinate is then used to sample (or fetch) a color from ourTexture.

Texture sampling has a loose interpretation and can be done in many different ways. It is thus our job to tell OpenGL how it should sample its textures.
{: .notice--warning}

## Texture Wrapping
Texture coordinates usually range from (0,0) to (1,1) but what happens if we specify coordinates outside this range? The default behavior of OpenGL is to **repeat the texture images** (we basically ignore the integer part of the floating point texture coordinate), but there are more options OpenGL offers:

* `GL_REPEAT:` The default behavior for textures. Repeats the texture image.
* `GL_MIRRORED_REPEAT:` Same as GL_REPEAT but mirrors the image with each repeat.
* `GL_CLAMP_TO_EDGE:` Clamps the coordinates between 0 and 1. The result is that higher coordinates become clamped to the edge, resulting in a stretched edge pattern.
* `GL_CLAMP_TO_BORDER:` Coordinates outside the range are now given a user-specified border color.

![Alt Text]({{ site.baseurl }}/assets/opengl/gl9.png)

Each of the aforementioned options can be set per coordinate axis (s, t (and r if you're using 3D textures) equivalent to x,y,z) with the `glTexParameter*` function:

* `GL_TEXTURE_WRAP_S` for the horizontal (x-axis) direction.
* `GL_TEXTURE_WRAP_T` for the vertical (y-axis) direction

```cpp
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
```

* The first argument specifies the texture target; we're working with 2D textures so the texture target is `GL_TEXTURE_2D.`
* The second argument requires us to tell what option we want to set and for which texture axis; we want to configure it for both the S and T axis.
* The last argument requires us to pass in the texture wrapping mode we'd like and in this case OpenGL will set its texture wrapping option on the currently active texture with `GL_MIRRORED_REPEAT.`

If we choose the `GL_CLAMP_TO_BORDER` option we should also specify a border color. This is done using the `fv` equivalent of the `glTexParameter` function with `GL_TEXTURE_BORDER_COLOR` as its option where we pass in a float array of the border's color value:

```cpp
float borderColor[] = { 1.0f, 1.0f, 0.0f, 1.0f };
glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor);
```

## Texture Filtering
Texture Filtering in OpenGL controls how textures are **sampled**! (So, filtering indeed happens right when you call `texture()` in the fragment shader.)

In OpenGL, textures are mapped to 3D objects and rendered at varying sizes depending on the distance and orientation of the object relative to the camera.

When the object is close to the camera, the texture might appear larger, making it necessary to **magnify** it. Conversely, when the object is far from the camera, the texture appears smaller, requiring **minification**.

### Magnification Filtering
Magnification occurs when a texture is displayed larger than its original size. For instance, if a small, low-resolution texture is displayed up close, each pixel (or texel) in the texture will need to cover a larger area on the screen.

Without proper filtering, this could result in a blocky or pixelated appearance because each texel becomes visibly large.
{: .notice--warning}

### Minification Filtering
Minification happens when a texture is displayed smaller than its original size. For example, a large texture applied to a distant object might need to shrink down significantly, meaning multiple texels in the texture are mapped to fewer pixels on the screen. 

Without filtering, minified textures can look noisy or exhibit aliasing artifacts (visual distortions like jagged edges).
{: .notice--warning}

### Filtering Options for Magnification and Minification
To improve texture quality when magnified or minified, OpenGL provides two filtering options:

#### `GL_NEAREST` 
The default texture filtering method, This mode selects the texel closest to the required texture coordinate. It doesn’t do any interpolation, resulting in a sharp but pixelated look. *(cross represents the exact texture coordinate)*

```cpp
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
```

![Alt Text]({{ site.baseurl }}/assets/opengl/gl11.png)

#### `GL_LINEAR` 
This mode interpolates between multiple nearby texels, creating a smooth, blended appearance. This is the most common choice for magnification filtering as it reduces pixelation. *(cross represents the exact texture coordinate)*

```cpp
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
```

![Alt Text]({{ site.baseurl }}/assets/opengl/gl12.png)

Visual effect of such a texture filtering method:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl10.png)

`GL_NEAREST` results in blocked patterns where we can clearly see the pixels that form the texture while `GL_LINEAR` produces a smoother pattern where the individual pixels are less visible. `GL_LINEAR` produces a more realistic output.

### Mipmaps
Imagine we had a large room with thousands of objects, each with an attached texture. There will be objects far away that have the same high resolution texture attached as the objects close to the viewer. 

Since the objects are far away and probably only produce a few fragments, OpenGL has difficulties retrieving the right color value for its fragment from the high resolution texture,

since it has to pick a texture color for a fragment that spans a large part of the texture. This will produce visible artifacts on small objects, not to mention the waste of memory bandwidth using high resolution textures on small objects.

To solve this issue OpenGL uses a concept called **mipmaps** that is basically a collection of texture images where each subsequent texture is twice as small compared to the previous one. 

after a certain distance threshold from the viewer, OpenGL will use a different mipmap texture that best suits the distance to the object. Because the object is far away, the smaller resolution will not be noticeable to the user. Then OpenGL is then able to sample the correct texels.
{: .notice--success}

Let's take a closer look at what a mipmapped texture looks like:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl13.png)

#### How Mipmaps Work
A typical mipmap chain consists of:

* Original Texture: Level 0
* Half-sized Version: Level 1
* Quarter-sized Version: Level 2
* ... and so on, down to the smallest 1x1 version

Each level in the mipmap chain is a power-of-two reduction of the previous level. So, if the original texture is 256x256, the next levels are 128x128, 64x64, 32x32, and so on.
{: .notice--success}

**Process**
1. Creating a collection of mipmapped textures for each texture image is cumbersome to do manually, but luckily OpenGL is able to do all the work for us with a single call to `glGenerateMipmap` after we've created a texture.

2. When rendering an object with a texture at a distance, OpenGL determines which mipmap level best matches the size of the texture on the screen.

3. After selecting the closest mipmap level, OpenGL samples the texels within that mipmap to produce the final color.

4. For example, if a texture will only occupy a small number of pixels, OpenGL might use a lower-resolution mipmap level, like Level 2 or 3, to avoid unnecessary detail that wouldn’t be visible.

When switching between mipmaps levels during rendering OpenGL may show some artifacts like sharp edges visible between the two mipmap layers. 
{: .notice--warning}

#### Filtering with Mipmaps

Just like normal texture filtering, it is also possible to filter between mipmap levels using `NEAREST` and `LINEAR` filtering for switching between mipmap levels.

To specify the filtering method between mipmap levels we can replace the original filtering methods with one of the following four options:

* `GL_NEAREST_MIPMAP_NEAREST:` takes the nearest mipmap to match the pixel size (size of the texture as it appears on the screen in terms of screen pixels) and uses nearest neighbor interpolation for texture sampling.
* `GL_LINEAR_MIPMAP_NEAREST:` takes the nearest mipmap level and samples that level using linear interpolation.
* `GL_NEAREST_MIPMAP_LINEAR:` linearly interpolates between the two mipmaps that most closely match the size of a pixel and samples the interpolated level via nearest neighbor interpolation.
* `GL_LINEAR_MIPMAP_LINEAR:` linearly interpolates between the two closest mipmaps and samples the interpolated level via linear interpolation.

Just like texture filtering we can set the filtering method to one of the 4 aforementioned methods using `glTexParameteri`:

```cpp
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
```

In OpenGL, mipmaps are only used for minification (when textures appear smaller on the screen), not for magnification (when textures appear larger). This is because mipmaps are designed specifically to handle the challenges that arise when a texture’s detail needs to be reduced, not when it needs to be increased
{: .notice--warning}

##### Process of Mipmaps with filtering

**Example of `GL_NEAREST_MIPMAP_NEAREST`**

Let’s say:
* Your texture's original resolution (Level 0) is 1024x1024.
* OpenGL determines that the texture will cover approximately a 256x256 area in screen pixels.(object with that texture is far away from the camera.)
* OpenGL chooses the 256x256 mipmap level (e.g., Level 2) since this resolution is closest to the display size.

With `GL_NEAREST_MIPMAP_NEAREST:`

* OpenGL looks up the texture coordinate in the 256x256 mipmap level.
* It picks the nearest texel in this mipmap level, with no interpolation between neighboring texels.

#### How to Enable and Generate Mipmaps
To use mipmaps in OpenGL, you need to enable mipmap filtering on the texture and either generate mipmaps automatically or supply each mipmap level manually.

##### Automatic Mipmap Generation
OpenGL can automatically generate mipmaps for a texture using `glGenerateMipmap:`

```cpp
// Bind your texture
glBindTexture(GL_TEXTURE_2D, textureID);

// Set minification filter to use mipmaps
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR); // Trilinear filtering

// Generate mipmaps
glGenerateMipmap(GL_TEXTURE_2D);
```

##### Manual Mipmap Generation
Alternatively, you can supply each mipmap level manually by calling glTexImage2D for each level. This approach is more complex and is typically used if you need custom mipmaps.

```cpp
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data); // Level 0
glTexImage2D(GL_TEXTURE_2D, 1, GL_RGB, width / 2, height / 2, 0, GL_RGB, GL_UNSIGNED_BYTE, data); // Level 1
// And so on for each level
```

## Loading and creating textures
The first thing we need to do to actually use textures is to load them into our application. so how do we get those images in our application? 

Just use an image-loading library that supports several popular formats and does all the hard work for us. A library like `stb_image.h.`

### stb_image.h
stb_image.h can be downloaded from [here](https://github.com/nothings/stb/blob/master/stb_image.h). Simply download the single header file, add it to your project as stb_image.h, and create an additional C++ file with the following code:

```cpp
#define STB_IMAGE_IMPLEMENTATION
#include "stb_image.h"
```

By defining `STB_IMAGE_IMPLEMENTATION` the preprocessor modifies the header file such that it only contains the relevant definition source code, effectively turning the header file into a .cpp file, and that's about it. Now simply include `stb_image.h` somewhere in your program and compile.

For the following texture sections we're going to use an image of a [wooden container](https://learnopengl.com/img/textures/container.jpg). To load an image using `stb_image.h` we use its `stbi_load` function:

```cpp
int width, height, nrChannels;
unsigned char *data = stbi_load("container.jpg", &width, &height, &nrChannels, 0); 
```

The function first takes as input the *location* of an image file. It then expects you to give three ints as its second, third and fourth argument that `stb_image.h` will fill with the resulting image's width, height and number of color channels. We need the image's **width and height** for generating textures later on.

### Generating a texture
Like any of the previous objects in OpenGL, textures are referenced with an ID; let's create one:

```cpp
unsigned int texture;
glGenTextures(1, &texture);  
```

The `glGenTextures` function first takes as input how many textures we want to generate and stores them in a unsigned int array given as its second argument (in our case just a single unsigned int).

Just like other objects we need to bind it so any subsequent texture commands will configure the currently bound texture:

```cpp
glBindTexture(GL_TEXTURE_2D, texture); 
```

Now that the texture is bound, we can start generating a texture using the previously loaded image data. Textures are generated with `glTexImage2D:`

```cpp
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
glGenerateMipmap(GL_TEXTURE_2D);
```

This is a large function with quite a few parameters so we'll walk through them step-by-step:

* The first argument specifies the texture target; setting this to `GL_TEXTURE_2D` means this operation will generate a texture on the currently bound texture object at the same target (so any textures bound to targets `GL_TEXTURE_1D` or `GL_TEXTURE_3D` will not be affected).

* The second argument specifies the mipmap level for which we want to create a texture for if you want to set each mipmap level manually, but we'll leave it at the base level which is 0.

* The third argument tells OpenGL in what kind of format we want to store the texture. Our image has only RGB values so we'll store the texture with RGB values as well.

* The 4th and 5th argument sets the width and height of the resulting texture. We stored those earlier when loading the image so we'll use the corresponding variables.

* The next argument should always be 0 (some legacy stuff).

* The 7th and 8th argument specify the format and datatype of the source image. We loaded the image with RGB values and stored them as chars (bytes) so we'll pass in the corresponding values.

* The last argument is the actual image data.

Once `glTexImage2D` is called, the currently bound texture object now has the texture image attached to it.

However, currently it only has the **base-level** of the texture image loaded and if we want to use **mipmaps** we have to specify all the different images manually (by continually incrementing the second argument) or, 

We could call `glGenerateMipmap` after generating the texture. This will **automatically** generate all the required mipmaps for the currently bound texture.

After we're done generating the texture and its corresponding mipmaps, it is good practice to free the image memory:

```cpp
stbi_image_free(data);
```

The whole process of generating a texture thus looks something like this:

```cpp
unsigned int texture;
glGenTextures(1, &texture);
glBindTexture(GL_TEXTURE_2D, texture);

// set the texture wrapping/filtering options (on the currently bound texture object)
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);	
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

// load and generate the texture
int width, height, nrChannels;
unsigned char *data = stbi_load("container.jpg", &width, &height, &nrChannels, 0);

if (data)
{
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
    glGenerateMipmap(GL_TEXTURE_2D);
}
else
{
    std::cout << "Failed to load texture" << std::endl;
}

stbi_image_free(data);
```

## Applying textures
Previously we had these vertices for quad:

```cpp
//define vertex input for triangle
float verticesQuad[] = {
	// Positions      // Colors
	0.5f,  0.5f, 0.0f,  1.0f, 0.0f, 0.0f,  // Top Right
	0.5f, -0.5f, 0.0f,  0.0f, 1.0f, 0.0f,  // Bottom Right
	-0.5f, -0.5f, 0.0f,  0.0f, 0.0f, 1.0f,  // Bottom Left
	-0.5f,  0.5f, 0.0f,  1.0f, 1.0f, 0.0f   // Top Left
};
```
Lets update it to have texture coordinate per each vertex:

```cpp
float verticesQuad[] = {
    // positions          // colors           // texture coords
     0.5f,  0.5f, 0.0f,   1.0f, 0.0f, 0.0f,   1.0f, 1.0f,   // top right
     0.5f, -0.5f, 0.0f,   0.0f, 1.0f, 0.0f,   1.0f, 0.0f,   // bottom right
    -0.5f, -0.5f, 0.0f,   0.0f, 0.0f, 1.0f,   0.0f, 0.0f,   // bottom left
    -0.5f,  0.5f, 0.0f,   1.0f, 1.0f, 0.0f,   0.0f, 1.0f    // top left 
};
```

Which means we need to update our vertex attribute setup!

```cpp
//position
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);
glEnableVertexAttribArray(0);

//color
glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(3 * sizeof(float)));
glEnableVertexAttribArray(1);

//tex coordinates -- NEW
glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));
glEnableVertexAttribArray(1);
```

Next we need to alter the vertex shader to accept the texture coordinates as a vertex attribute and then forward the coordinates to the fragment shader:

```cpp
#version 330 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aColor;
layout (location = 2) in vec2 aTexCoord;

out vec3 vertexColor; // Output color for the fragment shader
out vec2 texCoord;

void main ()
{
	gl_Position = vec4(aPos, 1.0);     // Position in clip space
	vertexColor = aColor;
    texCoord = aTexCoord;
}
```

The fragment shader should then accept the TexCoord output variable as an input variable.

The fragment shader should also have access to the **texture object**, but how do we pass the texture object to the fragment shader?

GLSL has a built-in data-type for texture objects called a sampler that takes as a postfix the texture type we want e.g. sampler1D, sampler3D or in our case **sampler2D.**

We can then add a texture to the fragment shader by simply declaring a uniform sampler2D that we later assign our texture to.

```cpp
#version 330 core

in vec3 vertexColor;    // Interpolated color from vertex shader
in vec2 texCoord;

uniform float alpha;
uniform sampler2D ourTexture;

out vec4 FragColor;     // Output color of the fragment

void main ()
{
    // Sample the texture color
    vec4 texColor = texture(ourTexture, texCoord);

	// Combine texture color with vertex color and apply alpha
    FragColor = vec4(texColor.rgb * vertexColor, texColor.a * alpha);

    //for simpler terms just do
    //FragColor = texture(ourTexture, texCoord);
}
```

The `texture` function then samples the corresponding color value using the texture parameters we set earlier. The output of this fragment shader is then the (filtered) color of the texture at the (interpolated) texture coordinate.
{: .notice--success}

All that's left to do now is to bind the texture before calling `glDrawElements` and it will then automatically assign the texture to the fragment shader's sampler:

```cpp
glBindTexture(GL_TEXTURE_2D, texture);
glBindVertexArray(VAO);
glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
```

If you did everything right you should see the following image:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl14.png)

## Texture Units
You probably wondered why the `sampler2D` variable is a uniform if we didn't even assign it some value with `glUniform`.! Using `glUniform1i` we can actually assign a location value to the texture sampler so we can set multiple textures at once in a fragment shader.

This location of a texture is more commonly known as a *texture unit.*

The default texture unit for a texture is 0 which is the default active texture unit so we didn't need to assign a location in the previous section; 

note that not all graphics drivers assign a default texture unit so the previous section may not have rendered for you.
{: .notice--warning}

The main purpose of texture units is to allow us to use more than 1 texture in our shaders. By assigning texture units to the samplers, we can bind to multiple textures at once as long as we activate the corresponding texture unit first. 

Just like `glBindTexture` we can activate texture units using `glActiveTexture` passing in the texture unit we'd like to use:

```cpp
glActiveTexture(GL_TEXTURE0); // activate the texture unit first before binding texture
glBindTexture(GL_TEXTURE_2D, texture);
```

After activating a texture unit, a subsequent `glBindTexture` call will bind that texture to the currently active texture unit.  Texture unit `GL_TEXTURE0` is always by default activated, so we didn't have to activate any texture units in the previous example when using `glBindTexture.`

OpenGL should have a at least a minimum of 16 texture units for you to use which you can activate using `GL_TEXTURE0` to `GL_TEXTURE15`. They are defined in order so we could also get `GL_TEXTURE8` via `GL_TEXTURE0 + 8` for example, which is useful when we'd have to loop over several texture units.
{: .notice--success}

We still however need to edit the fragment shader to accept another sampler. This should be relatively straightforward now:

```cpp

#version 330 core
...

uniform sampler2D texture1;
uniform sampler2D texture2;

void main()
{
    FragColor = mix(texture(texture1, TexCoord), texture(texture2, TexCoord), 0.2);
}
```

The final output color is now the combination of two texture lookups. GLSL's built-in `mix` function takes two values as input and linearly interpolates between them based on its third argument. 

If the third value is `0.0` it returns the first input; if it's `1.0` it returns the second input value. A value of `0.2` will return `80%` of the first input color and `20%` of the second input color, resulting in a mixture of both our textures.

We now want to load and create another texture; you should be familiar with the steps now. Make sure to create another texture object, load the image and generate the final texture using `glTexImage2D`. For the second texture we'll use an image of your facial expression [here](https://learnopengl.com/img/textures/awesomeface.png):

```cpp
unsigned char *data = stbi_load("awesomeface.png", &width, &height, &nrChannels, 0);
if (data)
{
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, data);
    glGenerateMipmap(GL_TEXTURE_2D);
}
```

Note that we now load a .png image that includes an alpha (transparency) channel. This means we now need to specify that the image data contains an alpha channel as well by using `GL_RGBA`; otherwise OpenGL will incorrectly interpret the image data.
{: .notice--warning}

To use the second texture (and the first texture) we'd have to change the rendering procedure a bit by binding both textures to the corresponding texture unit:

```cpp
// Activate texture unit GL_TEXTURE0 and bind texture1 to it
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, texture1);

// Activate texture unit GL_TEXTURE1 and bind texture2 to it
glActiveTexture(GL_TEXTURE1);
glBindTexture(GL_TEXTURE_2D, texture2);

glBindVertexArray(VAO);
glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 
```

We also have to tell OpenGL to which **texture unit each shader sampler belongs** to by setting each sampler using `glUniform1i`. We only have to set this once, so we can do this before we enter the render loop:

```cpp
ourShader.use(); // don't forget to activate the shader before setting uniforms!  

// set it manually -- 0 means telling that we use GL_TEXTURE0 - unit for this
glUniform1i(glGetUniformLocation(ourShader.ID, "texture1"), 0); 

// or with shader class -- 1 means telling that we use GL_TEXTURE1 - unit for this
ourShader.setInt("texture2", 1); 
  
while(...) 
{
    [...]
}
```

By setting the samplers via `glUniform1i` we make sure each uniform sampler corresponds to the proper **texture unit.** You should get the following result:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl15.png)

You probably noticed that the texture is **flipped upside-down!** This happens because OpenGL expects the 0.0 coordinate on the y-axis to be on the bottom side of the image, but images usually have 0.0 at the top of the y-axis.

Luckily for us, `stb_image.h` can flip the y-axis during image loading by adding the following statement before loading any image:

```cpp
stbi_set_flip_vertically_on_load(true);  
```

After telling `stb_image.h` to flip the y-axis when loading images you should get the following result:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl16.png)
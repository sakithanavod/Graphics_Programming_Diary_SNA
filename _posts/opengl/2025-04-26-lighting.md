---
title: "Lighting"
excerpt_separator: "<!--more-->"
categories:
 - OpenGL 
tags:
 - opengl
---
{% include mathJax.html %}

Lighting is one of the biggest milestones in OpenGL learning — you’re about to make your 3D scenes actually look 3D, not just flat.

<!--more-->

**Table of Contents**
* TOC
{:toc}

## Colors
In the digital world we need to map the (infinite) real colors to (limited) digital values and therefore not all real-world colors can be represented digitally. 

Colors are digitally represented using a red, green and blue component commonly abbreviated as RGB. Using different combinations of just those 3 values, within a range of [0,1], we can represent almost any color there is. For example, to get a coral color, we define a color vector as:

```cpp
glm::vec3 coral(1.0f, 0.5f, 0.31f); 
```

The color of an object we see in real life is not the color it actually has, but is the color **reflected** from the object. 
{: .notice--primary}

The colors that aren't absorbed (rejected) by the object is the color we perceive of it. As an example, the light of the sun is perceived as a white light that is the combined sum of many different colors.

If we would shine this white light on a blue toy, it would absorb all the white color's sub-colors **except** the blue color.
{: .notice--success}

Since the toy does not absorb the blue color part, it is **reflected.** This reflected light enters our eye, making it look like the toy has a blue color. The following image shows this for a coral colored toy where it reflects several colors with varying intensity:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl33.png)

You can see that the white sunlight is a collection of all the visible colors and the object absorbs a large portion of those colors. It only reflects those colors that represent the object's color and the combination of those is what we perceive (in this case a coral color).

Technically it's a bit more complicated, but we'll get to that in the PBR chapters.
{: .notice--warning}

These rules of color reflection apply directly in graphics-land. When we define a light source in OpenGL we want to give this light source a color. In the previous paragraph we had a white color so we'll give the light source a white color as well.

If we would then **multiply** the light source's color with an object's color value, the resulting color would be the reflected color of the object (and thus its perceived color).

Let's revisit our toy (this time with a coral value) and see how we would calculate its perceived color in graphics-land. We get the resulting color vector by doing a component-wise multiplication between the light and object color vectors:

```cpp
glm::vec3 lightColor(1.0f, 1.0f, 1.0f);
glm::vec3 toyColor(1.0f, 0.5f, 0.31f);
glm::vec3 result = lightColor * toyColor; // = (1.0f, 0.5f, 0.31f);
```

We can see that the toy's color absorbs a large portion of the white light, but reflects several red, green and blue values based on its own color value. This is a representation of how colors would work in real life. We can thus define an object's color as the amount of each color component it reflects from a light source. Now what would happen if we used a green light?

```cpp
glm::vec3 lightColor(0.0f, 1.0f, 0.0f);
glm::vec3 toyColor(1.0f, 0.5f, 0.31f);
glm::vec3 result = lightColor * toyColor; // = (0.0f, 0.5f, 0.0f);
```

As we can see, the toy has no red and blue light to absorb and/or reflect. The toy also absorbs half of the light's green value, but also reflects half of the light's green value. The toy's color we perceive would then be a dark-greenish color. We can see that if we use a green light, only the green color components can be reflected and thus perceived; no red and blue colors are perceived. As a result the coral object suddenly becomes a dark-greenish object. Let's try one more example with a dark olive-green light:

```cpp
glm::vec3 lightColor(0.33f, 0.42f, 0.18f);
glm::vec3 toyColor(1.0f, 0.5f, 0.31f);
glm::vec3 result = lightColor * toyColor; // = (0.33f, 0.21f, 0.06f);
```

As you can see, we can get interesting colors from objects using different light colors. It's not hard to get creative with colors.

But enough about colors, let's start building a scene where we can experiment in.

## A lighting scene
The first thing we need is an object to cast the light on and we'll use the infamous container cube from the previous chapters. We'll also be needing a light object to show where the light source is located in the 3D scene. For simplicity's sake we'll represent the light source with a cube as well (we already have the vertex data right?).

So, the first thing we'll need is a vertex shader to draw the container.

```cpp
#version 330 core
layout (location = 0) in vec3 aPos;

uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;

void main()
{
    gl_Position = projection * view * model * vec4(aPos, 1.0);
} 
```

Because we're also going to render a light source cube, we want to generate a new VAO specifically for the light source. We could render the light source with the same VAO and then do a few light position transformations on the model matrix, but in the upcoming chapters we'll be **changing the vertex data and attribute pointers of the container object quite often** and we don't want these changes to propagate to the light source object (we only care about the light cube's vertex positions), so we'll create a new VAO:

```cpp
unsigned int lightVAO;
glGenVertexArrays(1, &lightVAO);
glBindVertexArray(lightVAO);
// we only need to bind to the VBO, the container's VBO's data already contains the data.
glBindBuffer(GL_ARRAY_BUFFER, VBO);
// set the vertex attribute 
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
glEnableVertexAttribArray(0);
```

The code should be relatively straightforward. Now that we created both the container and the light source cube there is one thing left to define and that is the fragment shader for both the container and the light source:

```cpp
#version 330 core
out vec4 FragColor;
  
uniform vec3 objectColor;
uniform vec3 lightColor;

void main()
{
    FragColor = vec4(lightColor * objectColor, 1.0);
}
```

The fragment shader accepts both an object color and a light color from a uniform variable. Here we multiply the light's color with the object's (reflected) color like we discussed at the beginning of this chapter. Again, this shader should be easy to understand. Let's set the object's color to the last section's coral color with a white light:

```cpp

// don't forget to use the corresponding shader program first (to set the uniform)
lightingShader.use();
lightingShader.setVec3("objectColor", 1.0f, 0.5f, 0.31f);
lightingShader.setVec3("lightColor",  1.0f, 1.0f, 1.0f);
```

One thing left to note is that when we start to update these lighting shaders in the next chapters, the light source cube would also be **affected** and this is not what we want. We don't want the light source object's color to be affected the lighting calculations, but rather keep the light source isolated from the rest. 

We want the light source to have a constant bright color, unaffected by other color changes (this makes it look like the light source cube really is the source of the light).

To accomplish this we need to create a second set of shaders that we'll use to draw the light source cube, thus being safe from any changes to the lighting shaders. 

The vertex shader is the same as the lighting vertex shader so you can simply copy the source code over. The fragment shader of the light source cube ensures the cube's color remains bright by defining a constant white color on the lamp:

```cpp
#version 330 core
out vec4 FragColor;

void main()
{
    FragColor = vec4(1.0); // set all 4 vector values to 1.0
}
```

When we want to render, we want to render the container object (or possibly many other objects) using the lighting shader we just defined, and when we want to draw the light source we use the light source's shaders.

The main purpose of the light source cube is to show where the light comes from. We usually define a light source's position somewhere in the scene, but this is simply a position that has no visual meaning. 

To show where the light source actually is we render a cube at the same location of the light source. We render this cube with the light source cube shader to make sure the cube always stays white, regardless of the light conditions of the scene.

So let's declare a global vec3 variable that represents the light source's location in world-space coordinates:

```cpp
glm::vec3 lightPos(1.2f, 1.0f, 2.0f);
```

We then translate the light source cube to the light source's position and scale it down before rendering it:

```cpp
model = glm::mat4(1.0f);
model = glm::translate(model, lightPos);
model = glm::scale(model, glm::vec3(0.2f)); 
```

The resulting render code for the light source cube should then look something like this:

```cpp
lightCubeShader.use();
// set the model, view and projection matrix uniforms
[...]
// draw the light cube object
glBindVertexArray(lightCubeVAO);
glDrawArrays(GL_TRIANGLES, 0, 36);
```

Injecting all the code fragments at their appropriate locations would then result in a clean OpenGL application properly configured for experimenting with lighting. If everything compiles it should look like this:

## Basic Lighting

Lighting in the real world is extremely complicated and depends on way too many factors, something we can't afford to calculate on the limited processing power we have. Lighting in OpenGL is therefore based on approximations of reality using simplified models that are much easier to process and look relatively similar.

These lighting models are based on the physics of light as we understand it. One of those models is called the **Phong lighting model**. 

The major building blocks of the Phong lighting model consist of 3 components:

* ambient.
* diffuse.
* specular.

Each part models a different behavior of real light when it hits surfaces:

* **Ambient lighting:** even when it is dark there is usually still some light somewhere in the world (the moon, a distant light) so objects are almost never completely dark. To simulate this we use an ambient lighting constant that always gives the object some color.
* **Diffuse lighting:** simulates the directional impact a light object has on an object. This is the most visually significant component of the lighting model. The more a part of an object faces the light source, the brighter it becomes.
* **Specular lighting:** simulates the bright spot of a light that appears on shiny objects. Specular highlights are more inclined to the color of the light than the color of the object.

Phong Lighting = ambient + diffuse + specular
{: .notice--success}

Below you can see what these lighting components look like on their own and combined:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl34.png)

### Ambient lighting
Light usually does not come from a single light source, but from many light sources scattered all around us, even when they're not immediately visible. 

One of the properties of light is that it can scatter and bounce in many directions, reaching spots that aren't directly visible; light can thus reflect on other surfaces and have an indirect impact on the lighting of an object. 

Algorithms that take this into consideration are called **global illumination algorithms**, but these are complicated and expensive to calculate.

Since we're not big fans of complicated and expensive algorithms we'll start by using a very simplistic model of global illumination, namely **ambient lighting.** 

As you've seen in the previous section we use a small constant (light) color that we add to the final resulting color of the object's fragments, thus making it look like there is always some scattered light even when there's **not a direct light source.**

```cpp
void main()
{
    float ambientStrength = 0.1;
    vec3 ambient = ambientStrength * lightColor;

    vec3 result = ambient * objectColor;
    FragColor = vec4(result, 1.0);
}  
```

### Diffuse lighting
Ambient lighting by itself doesn't produce the most interesting results, but diffuse lighting however will start to give a significant visual impact on the object.

Diffuse lighting gives the object more brightness the closer its fragments are aligned to the light rays from a light source. To give you a better understanding of diffuse lighting take a look at the following image:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl35.png)

To the left we find a light source with a light ray targeted at a single fragment of our object. We need to measure at what **angle** the light ray touches the fragment. 

If the light ray is **perpendicular** to the object's surface the light has the greatest impact. To measure the angle between the light ray and the fragment we use something called a normal vector, that is a vector perpendicular to the fragment's surface (here depicted as a yellow arrow); 

we'll get to that later. The angle between the two vectors can then easily be calculated with the **dot product**.

You may remember from the transformations chapter that, 

* the lower the angle between two unit vectors, the more the dot product is inclined towards a value of 1. 
* When the angle between both vectors is 90 degrees, the dot product becomes 0. 
* the larger θ becomes, the less of an impact the light should have on the fragment's color.

The resulting dot product thus returns a scalar that we can use to calculate the light's impact on the fragment's color, resulting in differently lit fragments based on their orientation towards the light.
{: .notice--success}

So, what do we need to calculate diffuse lighting:

* Normal vector: a vector that is perpendicular to the vertex' surface.
* The directed light ray: a direction vector that is the difference vector between the light's position and the fragment's position. To calculate this light ray we need the light's position vector and the fragment's position vector.

#### Normal vectors
A normal vector is a (unit) vector that is perpendicular to the surface of a vertex. Since a vertex by itself has no surface (it's just a single point in space) we retrieve a normal vector by using its surrounding vertices to figure out the surface of the vertex. 

We can use a little trick to calculate the normal vectors for all the cube's vertices by using the cross product, but since a 3D cube is not a complicated shape we can simply manually add them to the vertex data. 

Try to visualize that the normals are indeed vectors perpendicular to each plane's surface (a cube consists of 6 planes).

Imagine a cube's front face:

Vertex Position         | Normal
-------------------------|--------------
$$(-0.5, -0.5, 0.5)$$     | $$(0, 0, 1)$$
$$( 0.5, -0.5, 0.5)$$     | $$(0, 0, 1)$$
$$( 0.5, 0.5, 0.5)$$      | $$(0, 0, 1)$$
$$(-0.5, 0.5, 0.5)$$      | $$(0, 0, 1)$$

* Each vertex on the front face has the same normal $$(0, 0, 1)$$ — facing outward along +Z.
* Same idea for each cube face, but with normals pointing outward along +X, -X, +Y, -Y, etc.

Since we added extra data to the vertex array we should update the cube's vertex shader:

```cpp
#version 330 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aNormal;
```

Now that we added a normal vector to each of the vertices and updated the vertex shader we should update the vertex attribute pointers as well. 

Note that the light source's cube uses the same vertex array for its vertex data, but the lamp shader has no use of the newly added normal vectors. 

We don't have to update the lamp's shaders or attribute configurations, but we have to at least modify the vertex attribute pointers to reflect the new vertex array's size:

```cpp
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);
glEnableVertexAttribArray(0);
```

We only want to use the first 3 floats of each vertex and ignore the last 3 floats so we only need to update the stride parameter to 6 times the size of a float and we're done.

All the lighting calculations are done in the fragment shader so we need to forward the normal vectors from the vertex shader to the fragment shader.
{: .notice--success}

```cpp
out vec3 Normal;

void main()
{
    gl_Position = projection * view * model * vec4(aPos, 1.0);
    Normal = aNormal;
} 
```

What's left to do is declare the corresponding input variable in the fragment shader:

```cpp
in vec3 Normal;
```

#### Calculating the diffuse color
We now have the normal vector for each vertex, but we still need the light's position vector and the fragment's position vector. Since the light's position is a single static variable we can declare it as a uniform in the fragment shader:

```cpp
uniform vec3 lightPos;
```

And then update the uniform in the render loop (or outside since it doesn't change per frame). We use the lightPos vector declared in the previous chapter as the location of the diffuse light source:

```cpp
lightingShader.setVec3("lightPos", lightPos);  
```

Then the last thing we need is the actual fragment's position. We're going to do all the lighting calculations in **world space** so we want a vertex position that is in world space first. 

We can accomplish this by multiplying the vertex position attribute with the *model matrix* only (not the view and projection matrix) to transform it to world space coordinates.

This can easily be accomplished in the vertex shader so let's declare an output variable and calculate its world space coordinates:

```cpp
out vec3 FragPos;  
out vec3 Normal;
  
void main()
{
    gl_Position = projection * view * model * vec4(aPos, 1.0);
    FragPos = vec3(model * vec4(aPos, 1.0));
    Normal = aNormal;
}
```

And lastly add the corresponding input variable to the fragment shader:

```cpp
in vec3 FragPos;
```
Each vertex of a triangle has a specific FragPos (its world-space position).
When the triangle is rasterized into many fragments (pixels):

* OpenGL smoothly interpolates (linearly blends) the FragPos between the three vertex FragPos values.
* Each fragment (pixel) gets its own interpolated FragPos! (Same for the normal).

This `in` variable will be interpolated from the 3 world position vectors of the triangle to form the `FragPos` vector that is the per-fragment world position. 
{: .notice--success}

This gives you a per-fragment world position and per-fragment normal — necessary for smooth lighting across surfaces.
{: .notice--primary}

Now that all the required variables are set we can start the lighting calculations.

**1. Calculate is the direction vector between the light source and the fragment's position**

The first thing we need to calculate is the direction vector between the light source and the fragment's position.

From the previous section we know that the light's direction vector is the difference vector between the light's position vector and the fragment's position vector. 

We also want to make sure all the relevant vectors end up as unit vectors so we normalize both the normal and the resulting direction vector:

```cpp
vec3 norm = normalize(Normal);

//vector pointing from the fragment toward the light - we need this direction
// to calculate angle between normal and light direction
vec3 lightDir = normalize(lightPos - FragPos);
```

**2. Calculate the diffuse impact of the light on the current fragment**

Next we need to calculate the diffuse impact of the light on the current fragment by taking the dot product between the norm and lightDir vectors. 

The resulting value is then multiplied with the light's color to get the diffuse component, resulting in a darker diffuse component the greater the angle between both vectors:

```cpp
float diff = max(dot(norm, lightDir), 0.0);
vec3 diffuse = diff * lightColor;
```

If the angle between both vectors is greater than 90 degrees then the result of the dot product will actually become negative and we end up with a negative diffuse component.
{: .notice--warning}

For that reason we use the `max` function that returns the highest of both its parameters to make sure the diffuse component (and thus the colors) never become negative. 

Now that we have both an ambient and a diffuse component we add both colors to each other and then multiply the result with the color of the object to get the resulting fragment's output color:

```cpp
vec3 result = (ambient + diffuse) * objectColor;
FragColor = vec4(result, 1.0);
```

So far the result would be:

```cpp
vec3 result = (ambient + diffuse) * objectColor;
```

**One last thing**
in the previous section we passed the normal vector directly from the vertex shader to the fragment shader. However, the calculations in the fragment shader are all done in world space, so shouldn't we transform the normal vectors to world space coordinates as well? 

Basically yes, but it's not as simple as simply multiplying it with a model matrix.

First of all, normal vectors are only direction vectors and do not represent a specific position in space. 

Second, normal vectors do not have a homogeneous coordinate (the w component of a vertex position). This means that translations should not have any effect on the normal vectors.

Example: 
* Positions (like vec4(x, y, z, 1.0)) use w = 1.0.
* W=1 means "this is a position in space."
* Direction vectors (like normals) would be vec4(x, y, z, 0.0) if expressed as a 4D vector.
* W=0 means "this is a pure direction," no translation should affect it.

So if we want to multiply the normal vectors with a model matrix we want to remove the translation part of the matrix by taking the upper-left 3x3 matrix of the model matrix (note that we could also set the w component of a normal vector to 0 and multiply with the 4x4 matrix).

Second, if the model matrix would perform a non-uniform scale, the vertices would be changed in such a way that the normal vector is not perpendicular to the surface anymore. The following image shows the effect such a model matrix (with non-uniform scaling) has on a normal vector:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl36.png)

Whenever we apply a non-uniform scale (note: a uniform scale only changes the normal's magnitude, not its direction, which is easily fixed by normalizing it) the normal vectors are not perpendicular to the corresponding surface anymore which distorts the lighting.

The trick of fixing this behavior is to use a different model matrix specifically tailored for normal vectors. This matrix is called the **normal matrix** and uses a few linear algebraic operations to remove the effect of wrongly scaling the normal vectors. 

The normal matrix is defined as 'the transpose of the inverse of the upper-left 3x3 part of the model matrix'.
{: .notice--success}

In the vertex shader we can generate the normal matrix by using the inverse and transpose functions in the vertex shader that work on any matrix type. Note that we cast the matrix to a 3x3 matrix to ensure it loses its translation properties and that it can multiply with the vec3 normal vector:

```cpp
Normal = mat3(transpose(inverse(model))) * aNormal;
```

Inversing matrices is a costly operation for shaders, so wherever possible try to avoid doing inverse operations since they have to be done on each vertex of your scene. For learning purposes this is fine, but for an efficient application you'll likely want to calculate the normal matrix on the CPU and send it to the shaders via a uniform before drawing (just like the model matrix).
{: .notice--warning}

### Specular Lighting
Similar to diffuse lighting, specular lighting is based on the light's direction vector and the object's normal vectors, but this time it is also based on the **view direction** e.g. from what direction the player is looking at the fragment.

Specular lighting is based on the reflective properties of surfaces. If we think of the object's surface as a mirror, the specular lighting is the **strongest** wherever we would see the light reflected on the surface. You can see this effect in the following image:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl37.png)

We calculate a reflection vector by **reflecting** the light direction around the normal vector. Then we calculate the angular distance between this reflection vector and the view direction.

The **closer** the angle between them, the greater the impact of the specular light. The resulting effect is that we see a bit of a highlight when we're looking at the light's direction reflected via the surface.

The *view vector* is the one extra variable we need for specular lighting which we can calculate using the viewer's world space position and the fragment's position. Then we calculate the specular's intensity, multiply this with the light color and add this to the ambient and diffuse components.

To get the world space coordinates of the viewer we simply take the position vector of the camera object (which is the viewer of course). So let's add another uniform to the fragment shader and pass the camera position vector to the shader:

```cpp
uniform vec3 viewPos;
```

```cpp
lightingShader.setVec3("viewPos", camera.Position); 
```

Now that we have all the required variables we can calculate the specular intensity. First we define a specular intensity value to give the specular highlight a medium-bright color so that it doesn't have too much of an impact:

```cpp
float specularStrength = 0.5;
```

Next we calculate the view direction vector and the corresponding reflect vector along the normal axis:

```cpp
vec3 viewDir = normalize(viewPos - FragPos);
vec3 reflectDir = reflect(-lightDir, norm); 
```

Note that we negate the `lightDir` vector. The reflect function expects the first vector to point from the light source towards the fragment's position, 

but the `lightDir` vector is currently pointing the other way around: from the fragment towards the light source (this depends on the order of subtraction earlier on when we calculated the `lightDir` vector). 

To make sure we get the correct reflect vector we reverse its direction by negating the `lightDir` vector first. The second argument expects a normal vector so we supply the normalized norm vector.

Then what's left to do is to actually calculate the specular component. This is accomplished with the following formula:

```cpp
float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32);
vec3 specular = specularStrength * spec * lightColor;  
```

We first calculate the dot product between the view direction and the reflect direction (and make sure it's not negative) and then raise it to the power of 32. This 32 value is the **shininess value of the highlight**.

The higher the shininess value of an object, the more it properly reflects the light instead of scattering it all around and thus the smaller the highlight becomes. Below you can see an image that shows the visual impact of different shininess values:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl38.png)

The only thing left to do is to add it to the ambient and diffuse components and multiply the combined result with the object's color:

```cpp
vec3 result = (ambient + diffuse + specular) * objectColor;
FragColor = vec4(result, 1.0);
```

We now calculated all the lighting components of the Phong lighting model. Based on your point of view you should see something like this:

![Alt Text]({{ site.baseurl }}/assets/opengl/gl39.png)

## Gouraud vs Phong shading

![Alt Text]({{ site.baseurl }}/assets/opengl/gl40.png)

Shading Model    | Where Lighting is Calculated     | What is Interpolated                  | Visual Result
-----------------|-----------------------------------|----------------------------------------|------------------------------------------------------
Gouraud Shading  | Lighting is calculated per vertex | Final color is interpolated across the triangle | Lighting can look faceted, highlights can be missed
Phong Shading    | Lighting is calculated per pixel (fragment) | Surface normals are interpolated across the triangle | Smooth, high-quality lighting, perfect highlights

[Download Lighting Source]({{ site.baseurl }}/assets/opengl/lighting_source.rar){:target="_blank"}